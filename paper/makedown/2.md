第 2 章 文本立场分析相关技术概述
# 2.1引言
本章概要介绍立场分析及其相关技术。首先从目前研究相对成熟的文本情感分析入手，分布从传统的基于规则、机器学习、深度学习分别讨论文本情感分析技术。由于本文主要以深度学习的方法解决社交媒体中立场分析，所以单独详细分析深度学习在文本情感分析的研究。随后,作为本文的重点研究对象,详细介绍了分别基于机器学习和深度学习模型的文本立场分析技术相关研究 本章总结了各项研究工作的特点,在分析优缺点的基础上,引出本文的后续研究。<br>
本章 2.2 节介绍情感分析的相关研究, 2.3 节介绍立场分析相关研究, 2.4节着重介绍基于深度学习模型的立场分析研究。

## 2.2文本情感分析相关技术概述
文本情感分析，指用自然语言处理、文本挖掘以及计算机语言学等方法来识别和提取原素材中的主观信息。通常来说，情感分析的目的是为了找出说话者，作者在某些话题上或者针对一个文本两极的观点的态度。这个态度或许是他或她的个人判断或是评估，也许是他当时的情感状态，或是作者有意向的情感交流。文本的情感分析是自然语音处理的重要研究内容之一，且其具有重要的科研价值与商业实用价值，吸引了大量的研究人员的关注。研究人员从不同的角度和不同方法对文本情感分析展开了研究。本节将从基于情感词典、机器学习和深度学习的三个方向分别概述近年来情感分析的研究进展。<br>

### 2.2.1基于情感词典的文本情感分析相关技术
基于情感词典的文本情感分析是早期研究人员的成果，其相应的模型建立在情感词典和语言学的规则基础上。由于模型的解释性好，需要计算资源较少，成为早期研究文本情感分析的主流。情感词典作为文本情感分析的重要组成部分能给文本情感分析提供重要的特征信息。情感词典的构造通常有语言学领域的专家完成。例如现有先对成熟的情感词典有WordNet、HowNet、大连理工大学中文情感词汇本来库等。基于情感词典的文本情感分析的技术步骤通常先匹配原文本中与情感词典相对应的情感表达特征词，然后根据各特征词的表达方式综合计算其每一个特征词的情感得分，最好结合整个文本的情感得分总结文本的情感倾向。<br>
Taboada【】在原来情感词典的基础上进一步考虑了词语的词性，结合情感词和词性综合给出情感的倾向得分。该情感分析模型包含一个语义指向计算器（Semantic　orientation　calculator，so－cal），这个计算器首先抽取出文本中的形容词、动词、名词以及副词等情感方位词，然后结合各种情感方位词计算原来文本的情感指向，模型结合的情感指向和强调、弱化、否定等转移的价位得到文本最终的情感倾向。作者通过一系列的实验证明了基于情感词典和此种转移规则的模型具有很强的鲁棒性，在跨领域的的文本情感分析上也有良好的表现。孙建旺【】等提出结合情感词典和机器学习两者的优势来解决微博情感分析的问题，利用微博多层次结构对微博文本进行特征降维。此外，由于微博包含多种颜文字，表情符等特点，设计了对颜文字和表情符的情感计算方法，其实验证明了加入表情符等特征，对微博的情感分析效果得到了提高。<br>
	基于不同的上下文可能决定某些情感词的特点，具有一定的领域相关性。例如“高”在“质量高”的上下文中表达的是正面的情感倾向，但是如果在“消费高”的上下文则表达负面的情感倾向。Bollegala【】等人结合了不同领域对情感词的表达特点构造了领域相关的情感词典。实验证明结合领域知识的情感词典能在相对于的领域取得更好的效果。Li【】提出一种相关领域自适应情感词的框架，能同步从标注训练语料中提取出的主题词和情感词，并进一步通过分析标注语料中主题词和情感词的关系来推导出未标注语料中与主题相关的情感词。<br>
    总体来看，基于情感词典/规则和知识库的情感分类准确率较高，但由于情感词典和常识库规模的限制，覆盖率较低。同时此类方法对分词、词性标注、规则匹配等的准确性要求较高，系统内部错误传递影响较大。[30]
## 2.2.2基于机器学习的文本情感分析相关技术
随着机器学习成功应用于其他领域的快速发展，对于文本情感分析的问题，大量的研究人员开始开展基于机器学习的文本情感分析的研究。基于机器学习的文本情感分析方法，首先通过特征工程抽取文本情感分析特征，然后通过抽取出来的特征词用机器学习能理解的数值表达文本。通过人工标注建立起特征表示数据和情感类标对的训练数据，通过各种已有的机器学习模型（支持向量机、朴素贝叶斯、逻辑回归、最大熵模型等）提取出训练集中特征和类标之间的映射关系的模型。Sida Wang【42】等利用N元词组（N-gram）对文本情感进行建模，模型结合了朴素贝叶斯与支持向量机的两个模型。首先利用朴素贝叶斯的思想，计算每一个词组的对数计数概率r，公式如下：
$$r=\log(\cfrac{\cfrac{p}{\|p_1\|}}{\cfrac{q}{\|q_1\|}})$$
$$p=\alpha + \sum_{i:y^{(i)}=1}f^{(i)}$$
$$p=\alpha + \sum_{i:y^{(i)}=-1}f^{(i)}$$
其中$y^{(i)}$为训练实例$i$的类标，$y^{(i)}\in\lbrace-1,1\rbrace$。其中$f^{(i)}$为训练实例$i$的特征向量，$f_{(i)}\in R^{\|V\|}$, $V$为特征集合 $\alpha$为平滑因子。<br>
于上述r的计算公式可知，从训练语料中可以计算出每一个词语对于不同情感的倾向大小，所以利用我们已经计算的每一个词的r值，可以得到文本的特征表示，特征表示后的文本可以作为支持向量机的输入，通过支持向量机可以抽取出训练集中有关文本情感分析的模式。<br>
Pang[8]等研究者创新性的把文本主题分析的技术迁移应用到文本情感分析中,文本的话题分类主要根据与话题相关的主题词决定，但是表达情感的方式更加的多样话，需要考虑的因素更多。Pang把文本的情感分析看成一类特殊的主题分析，使用了在有监督学习上泛化能力较好的支持向量机、朴素贝叶斯、最大熵模型三种基础的分类模型。选用的分类特征为一元词组（Unigram）、二元词组（Bigram）、词性分析（POS）、形容词位置信息等。此研究通过组合特征和模型的交叉验证表明，三个分类器组合任意一个特征特征的性能都比基线模型要好，在有关电影影评的数据集上，一元词组（Unigram）结合支持向量机的模型取得了良好的效果。但是此研究实验也论证了文本的情感分析的性能还是和文本主题分析存在较大的差距，同时也佐证了文本情感分析对模型和特征也有更高的要求。<br>
为了减少文本中无关的客观信息对文本情绪分析的干扰作用，Pang和lee对上述基于机器学习的文本情感分析模型进行了有正对性的改进，规避了文本客观消息的干扰，使模型更加专注于文本的主观信息。作者他们创新性把原来的文本情感分析问题转换成以各字句链接图中最小割问题，应用了挖掘图中的最小割的分类器来寻找对情感分析有用的主观表达的句子，从而屏蔽掉客观消息的干扰。此研究的实验也论证了剔除客观信息的文本情感分析模型的性能得到显著的加强。<br>
上述有关文本情感分析主要集中在有监督学习上，但有监督的学习需要大量的标注语料，同时需要保证以后的应用场景的数据和训练集合有着相同的分布，这在实际的应用场景上是很难达到的。有监督文本情感分析模型的泛化能力较弱，应用场景也相对较少。相关研究人员探索用无监督或者弱监督的途径解决文本情感分析。Read[21]等人提出的基于词语相似性的半监督方法。该研究首先在特定的词性上抽取双连词，然后通过通过分别计算双连词和正向情感词和负向情感词的互信息（Mutual Information）差来确定词的情感词性。研究提出当文本所有的双连词都为正向词性，则把文本归类为正向情感，若文本所有的双连词都为负向词性，也相应归类为负向情感。此研究的实验证明了此方法在汽车、电影、银行、旅游地等不同的文本领域取得较好的性能，模型在不同文本领域的泛化能力得到明显的加强。
## 2.2.2基于深度学习的文本情感分析相关技术
深度学习由于其更复杂的模型和更多的参数，比起以往的的机器学习方法在海量数据集上更有优势。且深度学习具有能够以端到端的形式构建模型的优势，不再需要人工筛选和总结大量特征，所以得到了情感分析研究者的关注。Socher等研究者为满足深度模型构建的需要，首先组织标注了斯坦福情感树库（Stanford Sentiment Treebank，SSTB）。斯坦福情感树库由11,855个电影评论句子组成，共包含215,154个不同短语，其中任意短语构成的节点和其他叶子节点均被标注为五类情感（强正面、正面、中性、负面、强负面）中的一个。Socher提出使用语法树和词汇向量表示任意长度的短语输入的递归神经张量网络，且其使用相同的张量组合函数来计算根节点向量，可得到句子中任意短语的情感向量表示。该模型可以利用树形结构捕捉情感变化和否定侧的作用范围，对于转折结构中情感表达识别同样具有很好的效果。实验证明，RNTN模型在五分类的情感分析及二分类（“正”、“负”）的情感分析中都取得了历史最好成绩。<br>
最简易的文字编码方法就是one-hot representation，向量长度为整个语料库中词的总个数。向量的分量只有一个1，其他全为0，1的位置对应该词在词典中的索引。但这种词向量表示有一些缺点，如容易受位数灾难的困扰，且不能很好地刻画词与词之间的相似性。另一种词向量是Distributed Representation，它最早是Hinton于1986年提出的，可以克服one-hot representation的上述缺点。其基本想法是：通过训练将某种语言中的每一个词映射成一个固定长度的短向量（这里的“短”是相对于one-hot representation的“长”而言的），所有这些向量构成一个词向量空间，而每一向量则可视为该空间中的一个点，在这个空间上引入“距离”，就可以根据词之间的距离来判断它们之间的（语法、语义）相似性。bengio[33]等人提出用神经网络的方式建立二元的语言模型，把词映射为低纬度稠密的词向量，并用词向量之间的距离来衡量词语之间语义的相似性。 Mnih[34]等人提出基础层次Log-Bilinear模型来训练神经网络中的语言模型。Mikolov[??]2013提出了Word2Vec模型，解决了词向量训练速度慢，效率低的缺点。其利用了CBOW（Continuous Bag-of-words Model）和Skip-Gram的两种语言模型。其中CBOW的思想是利用词语的上下文词的信息来预测该单词。而Skip-Gram则采取一种和CBOW相反的策略，用中间的词的消息来预测上下文的词。
# ！！有关CBow和skipgram的图！！
Mikolov创新性的提出了Hierarchical Softmax和负采样的词向量加速方法,为后续深度学习模型能在自然语言处理任务上打下了夯实的基础。对已经训练好的词向量，通过PCA等降维方法可在低纬度空间内实现可视化。
# 词向量可视化图片

循环神经网络(Recurrent Neural Networks-RNN)已经在众多自然语言处理任务上取得了巨大成功。不同于传统过得前向反馈神经网络的同层节点无连接层于层之间节点有连接，循环神经网络引入了定向循环，可以处理序列数据。RNN中最大的缺陷是后面时间的节点对于前面节点的感知力下降，当网络深时训练效果下降。LSTM可以解决这一问题，目前LSTM是RNN中使用最广泛最成功的模型。

卷积神经网络不仅在图像处理上表现优异，在文本分类上同样表现不俗。kim[]提出的多卷积核文本分类CNN模型。模型第一层为预先训练好的词向量或者是随机初始化参数的词向量Embedding层，然后接一个宽度和词向量维数相同，长度通常为3、4、5的多个卷积核的卷积层，卷积层后是是较少参数的池化层，最大值池化层在分类的效果较好。池化层后的输出为文本提取出来的特征向量，最后连接一个全连接作为分类层。实验证明CNN在情感分析上能较好的性能。

## 2.3文本立场分析相关技术
文本立场分析与文本情感分析有着本质的区别，文本立场分析更加关注文本反应出作者对于某一特定目标主题所持的立场和倾向。立场分析需要结合目标主题和情感信息，这比单独考虑文本的消息更加具有有挑战，对模型的建模能力也有更高的要求。