% !Mode:: "TeX:UTF-8" 

\BiChapter{融合注意力机制与条件编码的立场分析}{Methods of inserting figures}

近年来，有关深度学习的研究越来越深入，在各个领域取得了许多突破。基于注意力机制的神经网络成为研究的热点，引起了研究者的广泛关注。在社交媒体文本立场分析任务中，已有研究通常忽略主题目标信息对社交媒体立场分析的重要作用，这样建立模型存在的不合理性。注意力机制能根据主题目标信息对文本信息进行不同重要性的关注，使模型更加聚焦在重要的信息上。由于注意力机制与条件编码是从两种不同角度引入主题目标信息，本章提出一种融合注意力机制与条件编码的文本立场分析方法。实验结果表明，基于融合注意力机制与条件编码神经网络模型在社交媒体文本立场分析任务中取得了不错的效果，证明了融合注意力机制与条件编码神经网络的有效性。

本章的各节结构如下：4.1节介绍融合注意力机制与条件编码文本立场分析研究；4.2节为本章实验和结果分析；4.3节总结本章的内容。

\BiSection{融合注意力机制与条件编码文本立场分析研究}{Captions and descriptions of figures}

在社交媒体的文本立场分析上，当前研究通常没有有效把主题目标信息引入在文本的立场分析中，但是主题目标对文本立场分析又有着举足轻重的影响。为了弥补主题目标信息没有合适引入的缺点，本文提出一种以注意力机制引入主题目标信息。结合第三章所提出的条件编码成果，从注意力机制与条件编码两种不同方式引入主题目标信息，提出了一种融合注意力机制与条件编码神经网络的社交媒体文本立场分析的方法。

\BiSubsection{文本立场分析中的注意力机制}{}
注意力机制最早应用在图像识别领域上,研究人员研究的动机其实也是受到人类注意力机制的启发。人们在进行观察图像的时候,并不是一次就把整幅图像的每个位置像素都看过,大多是根据需求将注意力集中到图像的特定部分。而且人类会根据之前观察的图像学习到未来要观察图像注意力应该集中的位置。在文本立场分析中，不同的主题目标对文本中不同信息的关注度也会不一样。以下举出相应样例。

例3：“餐馆的菜品种类多，味道不错，但是服务人员的态度就不敢恭维了。”

若以“餐馆食物”为主题目标，关注点主要集中在“种类多”和“味道不错”等描述上，可以体现出文本对目标持“支持”的立场。但是若以“餐馆服务水平”为主题目标，关注点则需要集中在“不敢恭维”的信息上，此时文本对目标持“反对”的立场。因此不同的主题目标对原文本信息有不同的侧重点。而现有文本立场分析研究通常忽略此点，因此本文提出一种利用注意力机制使模型可以更关注与主题目标相关信息的方法。

注意力机制在自然语言处理中应用通常体现在“解码”过程中，例如基于注意力机制的神经网络翻译模型的编码过程与早期的神经网络翻译拥有相同的结构。主要是在不同点在于不同的“解码”过程。注意力机制的加入使得神经网络翻译模型具有更强的对句子翻译建模能力，使模型在翻译当前词语时关注和词语更相关的内容，忽略不相关的内容。在文本立场分析中，模型也需要对不同的信息进行取舍。由于不同主题目标对文本信息内容有着不同的侧重点为基础，本文将主题目标信息作为注意力导向，给予文本信息不同权重的关注度，在不同关注度的文本信息中挖掘文本立场分析的模式。
\begin{figure}[htbp]
	\centering
	\includegraphics[width = 0.7\textwidth]{liuchengtu.pdf}
	\caption[rnn_vanish]{融合注意力机制与条件编码的流程图}
	\label{liuchengtu}
\end{figure}

本文第三章提出的条件编码能在“编码”过程中，引入主题目标信息。相对于只单独编码文本信息，实验论证了条件编码能更好提取文中有关立场分析的模式从而提升文本立场分析的性能。而上述以注意力机制则是在“解码”过程中引入主题目标信息，使得模型能更好的关注与立场分析相关的信息。条件编码与注意力机制分别从“编码”与“解码”过程中引入了主题目标信息，因此本文提出一种融合注意力机制与条件编码的神经网络的文本立场分析的方法，处理过程如图~\ref{liuchengtu}~所示。

\BiSubsection{融合注意力机制与条件编码的文本立场分析模型}{}
本节以“深圳禁摩限电”为话题目标，微博文本“支持深圳交警，电单车继续治理”为例，按本节模型的5个层次，分别描述融合注意力机制与条件编码神经网络的立场分析的过程，具体模型的结构如图~\ref{GRU_CNN}~所示。
\begin{figure}[htbp]
	\centering
	\includegraphics[width = 1.0\textwidth]{attention.pdf}
	\caption[]{融合注意力机制与条件编码的社交媒体立场分析模型}
	\label{GRU_CNN}
\end{figure}

（1） 输入层

先将话题目标和微博文本经过预处理操作，然后通过分词工具把话题目标和微博文本进行划分，对于同一个话题目标，微博文本分词后句子长度有可能不一致，为了方便后续神经网络框架中的批量的并行计算，英文语料统计选择30为固定长度，中文语料统计后截取50为固定长度，长度超过固定长度进行截断操作，不够的进行补齐词表中规定 <PAD> 关键词。如上述微博文本最后转换成“支持深圳交警。电单车继续治理 <PAD> ... <PAD>”，而话题目标也需要进行分词操作，例如例子中“深圳禁摩限电”根据结巴分词分割成“深圳”、“禁摩”和“限电”三个词组。经过此层后主题目标信息和微博文本信息可以转换成以下形式，$m,n$分别为主题目标和微博文本的长度。
\begin{equation}\label{target_info} Target= \lbrace w_1,w_2...w_m\rbrace \end{equation}
\begin{equation}\label{text_info} Text=\lbrace w'_1,w'_2...w'_n\rbrace  \end{equation}

（2）词向量嵌入层

词向量的嵌入层，此层的功能是对输入的每一次词检索其词向量 （lookup操作），后续实验词向量的预训练由GloVe模型在大量无监督语料上训练得到，预训练的词向量维度为200，且把词向量设置为可训练，随神经网络模型的训练动态调整权重。经过此层后主题目标信息和微博文本信息可以转换成以下形式。
\begin{equation}\label{target_info} Target_v= \lbrace y_1,y_2...y_m\rbrace \end{equation}
\begin{equation}\label{text_info} Text_v=\lbrace x_1,x_2...x_n\rbrace \end{equation}

（3）主题目标编码与文本编码层

由于微博和Twitter文本立场分析中的主题目标包含的词语相对较少，为了减少模型的参数空间，因此编码主题目标信息的方法是单向LSTM模型。微博或Twitter文本包含了文本立场分析的绝大部分信息，双向的LSTM单元能比单向更好抽取文本中的信息，此处采用第三章节提出的条件编码技术编码文本信息，对于当前词的隐藏状态包含前向和后向的LSTM隐状态。具体的转换如以下公式所示。


\begin{equation}\label{lstm_f}[q_1~c_1] = LSTM^{target}(y_1,q_0,c_0)\end{equation}
\begin{equation}\label{lstm_f}[q_m~c_m] = LSTM^{target}(y_m,q_{M-1},c_{m-1})\end{equation}
\begin{equation}\label{lstm_f}[h^{→}_{1}~c^{→}_{1}] = LSTM^{→}(x_1,h_0,c_T)\end{equation}
\begin{equation}\label{lstm_f}[h^{→}_{n}~c^{→}_{n}] = LSTM^{→}(x_n,h^{→}_{n-1},c^{→}_{n-1})\end{equation}
\begin{equation}\label{lstm_f}[h^{←}_{n}~c^{←}_{n}] = LSTM^{←}(x_n,h_0,c_T)\end{equation}
\begin{equation}\label{lstm_f}[h^{←}_{1}~c^{←}_{1}] = LSTM^{←}(x_1,h^{←}_{2},c^{←}_{2})\end{equation}
\begin{equation}\label{lstm_f}h_i= [h^{→}_i~h^{←}_i]\end{equation}

（4）注意力机制计算与基于注意力的隐藏状态合成

通过结合主题目标编码信息$q_m$和微博的文本信息的基于双向LSTM模型的隐状态$h_i$，分别计算主题目标对每个词的关注程度，对于文本分析影响大的词，注意力机制会给予大的权重，反过来对于无用信息，注意力机制则会给予小的权重。分别计算每个词的权重后，原隐状态点乘注意力的权重形成基于注意力的隐藏状态，合并授予不同注意力的隐状态，具体的计算公式如下。
\begin{equation}\label{conv1} e_i=att(h_i,q)=W^t_n(tanh(W_{ah}h_i+W_{aq}q_m+b_a))+b_m \end{equation}
\begin{equation}\label{conv1} a_i=\frac{exp(e_i)}{\sum_{N}^{n=1}exp(e_n)} \end{equation}
\begin{equation}\label{conv1} h'_i=a_i \odot h_i \end{equation}
\begin{equation}\label{conv1} h = h'_i \end{equation}

（5）全连接分类层
把合并授予不同注意力的隐状态当做最后的特征向量，全连接层为Softmax归一化函数，输出的值为归一化到0-1之间的实数值，代表的意义为模型分类到某一个立场的概率，具体公式如下。
\begin{equation}\label{conv1} ouput_i=Softmax(Wh+b) \end{equation}


\BiSection{实验设置及结果分析}{hello}

本节主要介绍基于注意力机制的网络模在NLPCC2016中文立场分析数据集和SemEval2016英文立场分析数据集中的实验设置及结果分析。通过对样例的可视化注意力机制分析模型是否能抓取对主题目标其关键性作用的信息，解释模型能提高文本立场分析的性能的原因。本节包含两部分: 4.4.1小节简介有关实验的数据集、评价方法、数据预处理词和词向量的训练。4.4.2 小结介绍模型在两个数据集上的结果、对样例的注意力机制可视化结果分析和对比其他模型的结果与分析。


\BiSubsection{实验设置}{}

本章通过在中英文社交媒体数据集上的实验，验证基于注意力机制的神经网络模型在文本立场分析任务上的有效性。数据集包含NLPCC2016中立场分析数据集和SemEval2016英文立场分析数据集。由于本章实验使用与第三章实验一样的数据集，这里将不再赘述数据集的相关分布，有关数据集的详细分布参考第三章实验章节有关数据集的介绍，训练集、验证集与测试集的划分也与第三章相同。

有关评价方法也与第三章相同，对于同一个数据集内所以主题目标，分别计算其“支持”立场和“反对”立场的F1值，取其两者的平均值作为每个主题的平均F1值。模型在一个数据集上的总体性能通过无差别对待每一个主题目标计算总的“支持”立场与“反对”立场的F1值，两者F1值的平均数作为整个数据集的微平均F1值，微平均F1值代表了模型在数据集上的总体性能，其作为模型最重要的评价指标。有关F1值与微平均F1值的具体计算公式参考第三章的相关介绍，数据的预处理方式与第三章相同，这里将不再赘述。

\BiSubsection{实验结果及分析}{}
本文针对中英文数据集内容相差较大的特点，给两个不同的数据集设置不同的超参数，使模型在两个数据集上均取得较好的性能。取出训练集合的10\%作为验证集参与模型的选择。本章提出的基于注意力机制的神经网络的核心超参数主要集中在通过双向LSTM模块进行注意力矩阵和隐藏层的产生的循环神经网络的模块，最后在注意力矩阵作用下的隐藏层提取特征的网络模块。处理英文数据的双向LSTM的隐藏层的单元数为64，处理中文数据的双向LSTM的隐藏层单元数为100。对词向量抽取层的dropout概率为0.2，对LSTM内部记忆单元的dropout概率为0.3，批处理单元样本个数为16。对训练参数的L2正则项为1e-6。选取0.001的学习率的Adam优化方法。模型训练100轮，保留在验证集合性能最好的模型参数。具体参数参考表~\ref{param1}~。
\begin{table}[htbp]
	\caption[param]{基于注意力机制的神经网络模型超参数集}
	\label{param1}
	\vspace{0.5em}\centering\wuhao
	\begin{tabular}{ccc}
		\toprule[1.5pt]
		序号& 超参数名称 &数值\\
		\midrule[1pt]
		0 &词向量大小& 英文 100， 中文 200\\
		1 &LSTM隐藏层单元& 英文 64，中文 100\\
		4 &Embedding层dropout& 0.2\\
		5 &LSTM内部drought& 0.3\\
		6 &批处理大小& 32\\
		7 &L2 正则化参数 &1e-6\\
		8 &全量迭代次数& 50\\
		9 &梯度优化方法& Adam\\
		10 &学习率& 0.001\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}
使用上述超参数训练模型，基于注意力机制的网络模型在SemEval2016与英文立场分析数据集上的表现表~\ref{a_bi_gru_cnn_semeval}~所示。

如表~\ref{a_bi_gru_cnn_semeval}~所示，以下分析模型的结果。基于注意力机制的网络模型在所有主题目标下微平均F1值的指标为0.6897，其在所有主题目标“支持”立场的F1值为0.6378，而“反对”立场的总体F1值有0.7416。由于原始数据的分布，模型在“反对”立场的性能还是优于“支持”立场，原英文数据集的分布如表~\ref{englishdata}~所示。模型对各个主题目标的性能有较大的差异，在“Athesim”主题目标下性能能达到0.6708，而在主题目标“Climate Change is a Real Concern”中，由于训练集中“支持”立场是“反对”立场的10多倍，模型还是没有克服这个数据分布的缺陷，没有将任意一个样本分类为“反对”立场。

\begin{table}[htbp]
	\caption[table123]{基于注意力机制的网络模型在各个话题试验性能（SemEval英文立场分析数据集）}
	\label{a_bi_gru_cnn_semeval}
	\vspace{0.5em}\centering\wuhao
	\begin{tabular}{cccccccc}
		\toprule[1.5pt]
		主题目标& $P_{favor}$&$R_{favor}$&$F_{favor}$&$P_{against}$&$R_{against}$&$F_{against}$&$F_{average}$ \\
		\midrule[1pt]
		Atheism&0.5172&0.4688&0.4918&0.8693&0.8313&0.8498&0.6708\\
		Climate Change&0.7321&1.0000&0.8454&0.0000&0.0000&0.0000&0.4227\\
		Feminist Movement&0.4231&0.3793&0.4000&0.7661&0.7158&0.7401&0.5701\\
		Hillary Clinton&0.4423&0.5111&0.4742&0.6733&0.7907&0.7273&0.6007\\
		Legal. of Abortion&0.6061&0.4348&0.5063&0.7718&0.6085&0.6805&0.5934\\
		合并统计&0.6078&0.6678&0.6378&0.7630&0.7203&0.7416&0.6897\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

\begin{table}[htbp]
	\caption[table123]{基于注意力机制的网络模型在各个话题试验性能（NLPCC2016中文立场分析数据集）}
	\label{chinese_a_bi_gru_cnn_semeval}
	\vspace{0.5em}\centering\wuhao
	\begin{tabular}{cccccccc}
		\toprule[1.5pt]
		主题目标& $P_{favor}$&$R_{favor}$&$F_{favor}$&$P_{against}$&$R_{against}$&$F_{against}$&$F_{average}$ \\
		\midrule[1pt]
		iPhone SE&0.6479&0.6133&0.6301&0.6970&0.4423&0.5412&0.5857\\
		春节放鞭炮&0.7263&0.7841&0.7541&0.7912&0.7660&0.7784&0.7662\\
		俄在叙反恐行动&0.6579&0.5319&0.5882&0.5566&0.6860&0.6146&0.6014\\
		开放二胎政策&0.7961&0.8283&0.8119&0.8765&0.7474&0.8068&0.8093\\
		深圳禁摩限电&0.6353&0.8571&0.7297&0.8667&0.8273&0.8465&0.7881\\
		合并统计&0.7000&0.7184&0.7092&0.7550&0.6933&0.7241&0.7167\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

在NLPCC2016中文立场分析数据集上，各主题目标的性能如表~\ref{chinese_a_bi_gru_cnn_semeval}~所示。基于注意力机制的网络模型在所有主题目标下微平均F1值的指标为0.7167，其在所有主题目标“支持”立场的F1值为0.7092，而“反对”立场的总体F1值有0.7241，“支持”立场与“反对”立场在整体的F1值较为相近，因此模型在此数据集上的微平均F1值也比英文数据集高2.70\%。由于中文数据集在各主题目标下立场类标分布相对较平均，没有出现与英文数据集中“Climate Change is a Real Concern”单个主题目标平均F1值只有0.4的结果，但是模型在各个不同主题目标下的性能还是有较大的差距，模型在“开放二胎政策”的主题目标下平均F1值达到了0.8093，但是在“俄在叙反恐行动”主题目标下的平均F1值只有0.581，体现了不同主题目标下，立场分析难易程度也相差较大。

为了验证本章提出的融合注意力机制与条件编码网络模型的有效性和不足之处，以下通过实验结果对比其他研究人员在文本研究中模型。由于两个数据集来源于不同的评测任务，因此分别从SemEval2016英文立场分析数据集和NLPCC2016中文立场分析数据集挑选出较好系统和本章提出的基于注意力机制的网络模型进行比较。

在SemEval英文立场分析数据集合上，引入以下模型是作为对比模型。

（1）MITRE \citeup{zarrella2016mitre}， SemEval2016立场分析评测任务第一名，模型详细介绍参考第三章实验部分。

（2）SVM  \citeup{mohammadstance} 2017 Mohammad所提出基于n-gram,POS,sentiment等特征的SVM模型

（3）BiText-On-Target 第三章提出的基于主题目标的条件的双向LSTM文本编码模型，模型详细介绍参考第三章实验部分。

（4） Att-BiText-on-Target 本章提出的结合注意力机制与条件编码的神经网络模型。

四个模型在SemeEval2016的各主题目标下单个平均F1值如图~\ref{chart_semeval_best_model_attention}~所示。
\begin{figure}[htbp]
	\centering
	\includegraphics[width = 0.85\textwidth]{chart_semeval_best_model_attention.png}
	\caption[rnn_vanish]{模型在SemEval2016英文立场分析数据集各主题目标性能分析对比}
	\label{chart_semeval_best_model_attention}
\end{figure}

本文提出的融合条件编码与注意力机制的网络模型在“Atheism”、”Climate Change is a Real Concern“和“Hillary Clinton”主题目标下分别取得了0.671、0.423和0.600的平均F1值，均在四个模型中取得最佳性能。基于特征工程的模型SVM在“Legal of Abortion”依旧取得最高性能，比其他三个基于深度学习的模型都要高，其具体的原因可能是在此主题目标上分类需要建立人工参与的特征，而深度学习模型在数据较少的情况下无法提取出此类特征。融合条件编码与注意力机制网络模型在英文数据集各个话题中都取得较高的性能，一定程度反应了此模型在解决文本立场分析中的有效性。

上述模型在SemEval数据集下的综合“支持”和“反对”的F1值和总体微平均F1值的性能如表~\ref{semeval_attention_res}~所示。


本章提出的融合条件编码与注意力机制网络在英文数据集总体的“支持”立场的F1值为0.637，“反对”立场的F1值为0.747，总体立场分析的微平均F1值为0.689。对比其他三个模型，融合条件编码与注意力机制网络在“反对”立场平均F1值与总体微平均F1值均取得最高性能。比只用条件编码的BiText-On-Target模型高1.7\%。Att-BiText-on-Target优于SemEval所有评测模型，微平均F1值比评测任务的最佳模型MITRE高1.08\%，比Mohammad在2017所提出的基于n-gram,POS,sentiment等特征的SVM模型高0.60\%。MITRE模型需要大量的无标注Twitter语料，SVM模型需要手工构造一些人为选择的特征。从上述对比中验证融合条件编码与注意力机制的网络模型在英文Twitter立场分析有效性。

\begin{table}[htbp]
	\caption[table123]{各模型在立场分析测试集中的性能表现（SemEval英文立场分析数据集）}
	\vspace{0.5em}\centering\wuhao
	\label{semeval_attention_res}
	\begin{tabular}{cccccccc}
		\toprule[1.5pt]
		模型& $F_{favor}$&$F_{against}$&$F_{average}$ \\
		\midrule[1pt]
		MITRE\citeup{zarrella2016mitre}&0.5932&\textbf{0.7633}&0.6782\\
		SVM\citeup{mohammadstance} &-&-&0.6830\\
		BiText-On-Target&0.6112&0.7314&0.6713\\
			Att-BiText-on-Target&\textbf{0.6378}&0.7478&\textbf{0.6897}\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

上述统计说明模型在SemEval英文立场分析数据集的性能，以下将在NLPCC2016中文立场分析数据集对比评测中的模型，对比的模型如下所示。

（1）RUC-MMC\citeup{xu2016overview}模型详细介绍参考第三章实验部分。

（2）Top-Team \citeup{xu2016overview}模型详细介绍参考第三章实验部分。

（3） BiText-On-Target 第三章提出的基于主题目标的条件的双向LSTM文本编码模型，模型详细介绍参考第三章实验部分。

（4） Att-BiText-on-Target 本章提出的结合注意力机制与条件编码的神经网络模型。

四个模型在SemeEval2016的各主题目标下单个平均F1值如图~\ref{chart_nlpcc_best_model_attention}~所示。
\begin{figure}[htbp]
	\centering
	\includegraphics[width = 1.0\textwidth]{chart_nlpcc_best_model_attention.png}
	\caption[rnn_vanish]{模型在NLPCC2016中文立场分析各主题目标性能分析对比}
	\label{chart_nlpcc_best_model_attention}
\end{figure}


本章节提出融合条件编码与注意力机制网络模型在“开发二胎”主题目标下0.809的平均F1值，并在“深圳禁摩限电”主题目标下取得0.7881的平均F1值的。基于提取主题目标的关键字典的Top-Team在“深圳禁摩限电”主题目标上取得最好的0.794平均F1值，说明基于特征的传统机器学习方法解决特定主题目标还是有一定的优势的。融合条件编码与注意力机制的网络模型在三个“IphoneSE”、“开放二胎”和“深圳禁摩限电”主题目标下平均F1值均高于评测系统最佳RUC-MCC模型。通过融合第三章所提出的条件编码模型，Att-BiText-on-Target模型在“春节鞭炮”，“俄罗斯反恐行动”，“开放二胎”，“深圳禁摩限电”四个主题目标任务下均比原模型条件编码BiText-On-Target具备更好的性能。融合条件编码与注意力机制网络模型在三个主题目标均取得最优性能，并且在其余两个主题目标下也有相对较好的性能，说明模型在中文文本立场分析任务中的有效性。

上述模型在NLPCC中文立场分析数据集下的综合“支持”和“反对”的F1值和总体微平均F1值的性能如表~\ref{nlpcc_res_attention}~所示。
\begin{table}[htbp]
	\caption[table123]{各模型在立场分析测试集中的性能表现（NLPCC2016中文立场分析数据集）}
	\label{nlpcc_res_attention}
	\vspace{0.5em}\centering\wuhao
	\begin{tabular}{cccccccc}
		\toprule[1.5pt]
		模型& $F_{favor}$&$F_{against}$&$F_{average}$ \\
		\midrule[1pt]
		RUC-MMC\citeup{xu2016overview}&0.6969&\textbf{0.7243}&0.7106\\
		Top-Team\citeup{xu2016overview}&0.6601&0.7186&0.6894\\
		BiText-On-Target&0.6761&0.7158&0.6984\\
	Att-BiText-on-Target&\textbf{0.7092}&0.7241&\textbf{0.7167}\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

本章节提出融合注意力机制与条件编码网络模型在NLPCC2016中文立场分析数据集上取得“支持”立场平均F1值为0.7092，“反对”立场的平均F1值为0.7241，总体微平均F1值为0.716，在所对比模型中取得最优性能，模型性能比NLPCC2016中文立场分析评测最好的模型RUC-MMC在微平均上高了0.61\%，说明模型在中文立场分析任务中的有效性。模型比第三章节提出的基于条码编码的BiText-On-Target模型高了1.7\%。证明在中文文本立场分析中，融合注意力机制与条件编码网络模型比条件编码模型更能建模有主题目标信息和文本信息的立场分析任务。

为验证注意力机制与条件编码在结合主题目标信息与文本信息的作用，论证以注意力机制与条件编码能否提高文本立场分析的性能，设计以下对比实验。
\begin{table}[htbp]
	\caption[table123]{模型比较}
	\label{model_list_attention}
	\vspace{0.5em}\centering\wuhao
	\begin{tabular}{cccccccc}
		\toprule[1.5pt]
		模型&文本编码方式&是否引入主题目标&引入主题目标方式 \\
		\midrule[1pt]
		BiText&双向LSTM&否&无\\
		BiText-on-Target&双向LSTM&是&条件编码\\
		Att-BiText&双向LSTM&是&注意力机制\\
		Att-BiText-on-Target&双向LSTM&是&条件编码\&注意力机制\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

双向LSTM独立编码文本信息模型，以下简称\textbf{BiText}。

本文第三章所提出的模型，基于条件编码文本的双向LSTM模型结合主题目标信息与文本信息以下简称\textbf{BiText-on-Target}。

以主题目标信息作为注意力机制的导向，对文本信息进行注意力权重的加权模型，以下简称\textbf{Att-BiText}。

以主题目标信息为条件编码文本信息，主题目标信息作为注意力机制的导向，对条件编码后文本信息进行注意力权重加权模型，模型的细节参考图~\ref{GRU_CNN}以下简称\textbf{Att-BiText-on-Target}。

四个模型建模的具体区别如表~\ref{model_list_attention}所示。

\begin{figure}[htbp]
	\centering
	\includegraphics[width = 1.0\textwidth]{chart_attention_condition_semeval.png}
	\caption[rnn_vanish]{模型在SemEval2016各主题目标性能分析对比}
	\label{chart_attention_condition_semeval}
\end{figure}
上述对比模型在英文数据集上各主题目标的平均F1值如图~\ref{chart_attention_condition_semeval}所示，BiText模型除了在“Climate”主题目标上性能能和其他三个模型持平外，在另外4个主题目标下的性能都明显低于引入了主题目标信息的模型，此现象证明了合理引入主题目标信息对文本立场分析有显著的促进作用。第三章所提出的BiText-on-Target模型在“Feminist Movement”与“Hillary Clinton”主题目标下比本章提出的只用注意力机制的神经网络Att-BiText模型性能要高一些，同时Att-BiText模型在“Atheism”和“Abortion”主题目标下性能优于BiText-on-Target模型。因此可以看出两种引入主题目标信息的方式各有优劣，这也促使本文提出融合这两种方式的Att-BiText-on-Target模型。从实验的结果可以看出融合后的Att-BiText-on-Target模型在“Atheism”、“Feminist Movement”与“Hillary Clinton”主题目标下均超过融合前两者的模型，验证了融合条件编码与注意力机制的两种引入主题目标信息的方式的有效性。

汇总中英文数据集上各模型的总体“支持”与“反对”立场的F1值与微平均F1值如表~\ref{semeval_all_model1}~与~\ref{nlcpp_all_model1}~所示。
\begin{table}[htbp]
	\caption[table123]{模型整体性能对比（SemEval2016英文立场分析数据集）}
	\label{semeval_all_model1}
	\vspace{0.5em}\centering\wuhao
	\begin{tabular}{cccccccc}
		\toprule[1.5pt]
		模型& $P_{favor}$&$R_{favor}$&$F_{favor}$&$P_{against}$&$R_{against}$&$F_{against}$&$F_{average}$ \\
		\midrule[1pt]
		BiText&0.5970&0.5263&0.5617&0.7054&0.7902&0.7478&0.6547\\
		BiText-on-Target&0.5743&0.6480&0.6112&0.7396&0.7231&0.7314&0.6713\\
		Att-BiText&0.5778&0.6842&0.6310&0.7707&0.6629&0.7168&0.6739\\
		Att-BiText-on-Target&0.6078&0.6678&0.6378&0.7630&0.7203&0.7416&\textbf{0.6897}\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

\begin{table}[htbp]
	\caption[table123]{模型整体性能对比（NLPCC2016中文立场分析数据集）}
	\label{nlcpp_all_model1}
	\vspace{0.5em}\centering\wuhao
	\begin{tabular}{cccccccc}
		\toprule[1.5pt]
		模型& $P_{favor}$&$R_{favor}$&$F_{favor}$&$P_{against}$&$R_{against}$&$F_{against}$&$F_{average}$ \\
		\midrule[1pt]
		BiText&0.6565&0.6706&0.6636&0.7186&0.6892&0.7039&0.6837\\
		BiText-on-Target&0.6721&0.6850&0.6785&0.7146&0.7219&0.7182&0.6984\\
		Att-BiText&0.6537&0.7208&0.6872&0.7506&0.6646&0.7076&0.6974\\
		Att-BiText-on-Target&0.7000&0.7184&0.7092&0.7550&0.6933&0.7241&\textbf{0.7167}\\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

BiText模型在中英文数据集中取得0.654和0.683的微平均F1值，以条件编码引入主题目标信息的BiText-on-Target模型在中英文数据集上的微平均F1值为0.671与0.698。以条件编码引入主题目标信息显著的提升了模型的性能，第三章也有相应的实验论证了上述结论。以注意力机制引入主题目标信息的Att-BiText模型在在中英文数据集上的微平均F1值为0.671与0.697。与条件编码的模型性能相近，但从在英文数据集上各主题目标的性能分析图~\ref{chart_attention_condition_semeval}中可以看出，两模型在不同的主题目标任务下各有优劣。因此本文提出融合条件编码与注意力机制这两种引入主题目标信息的Att-BiTe   xt-on-Target模型。

Att-BiText-on-Target模型在中英文数据集上取得微平均F1值分别为0.689与0.716，相对于BiText模型分别提高了3.5\%与3.3\%，相对于不引入主题目标信息有显著的提升。Att-BiText-on-Target模型相对于单独的条件编码的BiText-on-Target分别提升了1.7\%与1.9\%，相对于单独的注意力机制的Att-BiText模型分别提高了1.4\%与1.8\%。表明融合两种引入主题目标信息方法在中英文数据集上都取得高于原模型的性能，从各主题目标任务下性能分析图~\ref{chart_attention_condition_semeval}可知Att-BiText-on-Target模型在“Atheism”、“Feminist Movement”与“Hillary Clinton”主题目标下有着显著的提升。总上所述，对比实验验证融合注意力机制与条件编码两种引入主题目标信息的Att-BiText-on-Target模型的有效性。

\begin{figure}[htbp]
	\centering
	\includegraphics[width = 1.0\textwidth]{semEval-attention-weight.pdf}
	\caption[rnn_vanish]{融合模型注意力权重矩阵（SemEval2016英文立场分析数据集）}
	\label{semEval-attention-weight}
\end{figure}
为进一步验证注意力机制能较好的关注文本中对主题目标立场分析有帮助的内容，将在中英文语料中选取相应的语料进行注意力权重的可视化表示，图~\ref{semEval-attention-weight}~列举出SemEval2016英文立场分析数据集语料中一个样例的注意力矩阵的可视化。举例的主题目标为“Hillary　Clinton”，Twitter文本信息为“ @hillaryclinton ~interview ~was ~ridiculous !! she's ~such~ a ~liar ! ”。
模型把注意力主要集中在“＠hillaryClinton”和“ridiculous”两个词组中，模型也正确给出了立场的预测为“反对”立场。如果人类面对上述重点关注词也和容易推导出文本对“Hillary Clinton”主题目标持“反对”的立场，因此说明在英文语料中融合注意力机制与条件编码模型能根据主题目标信息较好地关注对主题目标立场分析起关键性作用的词语。

\begin{figure}[htbp]
	\centering
	\includegraphics[width = 1.0\textwidth]{nlpcc-attention-weight.pdf}
	\caption[rnn_vanish]{融合模型注意力权重矩阵（NLPCC2016中文立场分析数据集）}
	\label{nlpcc-attention-weight}
\end{figure}

图~\ref{nlpcc-attention-weight}~列举出NLPCC2016中文立场分析数据集语料中一个样例的的注意力矩阵的可视化。举例的主题目标为“深圳禁摩限电”，微博文本信息为“支持打击，满街都是电动车在乱串”。由于结巴分词工具把“乱串”分词为“乱”和“串”两个词，而“串”在训练语料中为低频词，因此预处理其为“\_UNK\_”关键词。相对于在英文语料上的注意力权重的分配，在中文数据集上的注意力权重分布则相对分散些。注意力机制主要集中在“支持”，“打击”，“是”，“电动车”四个词中，模型也正确给出了立场的预测为“支持”立场。如果人类面对上述重点关注词也和容易推导出文本对“深圳禁摩限电”主题目标持“支持”的立场。同样的在中文语料中，融合注意力机制与条件编码模型能根据主题目标信息较好地关注对主题目标立场分析起关键性作用的词语。

通过上述两个例子可以说明融合注意力机制与条件编码的模型能根据主题目标信息较好关注对主题目标立场分析起关键性作用的词语，侧面验证本文提出的融合注意力机制与条件编码模型的合理性与有效性。


\BiSection{本章小结}{}

本章介绍了基于融合注意力机制与条件编码网络模型在文本立场分析上的工作。受注意力机制在图像处理、语音识别、机器翻译上性能的突破的启发，将注意力机制引入文本立场分析任务中。将文本立场分析中主题目标作为注意力导向，给予文本信息不同权重的关注度，其后在已经授予不同关注度文本信息中挖掘有关立场分析的模式。同时受到第三章所提出条件编码能更好的编码文本信息的启发，提出融合注意力机制与条件编码文本立场分析的方法。为验证最终模型的有效性，分别在中英文数据集上进行了实验，在SemEval2016英文立场分析数据集上取得0.689的微平均F1值，相对于评测最优系统提升了1.08\%，相对于Mohammad在2017年提出的基于特征的SVM模型提高了0.60\%。在NLPCC中文立场分析数据集上取得0.716的微平均F1值，相对于评测最优系统提高了0.61\%。本章节提出的融合条件编码与注意力机制网络模型在中英文均取得很好的性能。证明了的融合注意力机制与条件编码网络模型在文本立场分析任务上是有效的。



