% !Mode:: "TeX:UTF-8" 

\BiChapter{文本立场分析相关技术概述}{Methods of inserting figures}

\BiSection{引言}{2.1}
本章概要介绍立场分析及其相关技术。首先从目前研究相对成熟的文本情感分析入手，分别从传统的基于规则、机器学习、深度学习分别讨论文本情感分析技术。由于本文主要以深度学习的方法解决社交媒体中立场分析，所以详细分析深度学习在文本情感分析的研究。作为本文的重点研究对象详细介绍了分别基于机器学习和深度学习模型的文本立场分析技术相关研究 本章总结了各项研究工作的特点，在分析优缺点的基础上引出本文的后续研究



\BiSection{文本情感分析相关技术概述}{2.2}
文本情感分析，指应用自然语言处理、文本分析、计算机语言学等技术系统的定位、提取、量化文本信息中作者所有表达的个人主观信息。文本的情感分析是自然语音处理的重要研究内容之一，且其具有重要的科研价值与商业实用价值，吸引了大量的研究人员的关注。研究人员从不同的角度和不同方法对文本情感分析展开了研究。本节将从基于情感词典、机器学习和深度学习的三个方向分别概述近年来情感分析的研究进展。


\BiSubsection{基于情感词典的文本情感分析相关技术}{2.2.1}
基于情感词典的文本情感分析是早期研究人员的成果，其相应的模型建立在情感词典和语言学的规则基础上。由于模型的解释性好，需要计算资源较少，成为早期研究文本情感分析的主流。情感词典作为文本情感分析的重要组成部分能给文本情感分析提供重要的特征信息。情感词典的构造通常由语言学领域的专家完成。例如现有相对成熟的情感词典有WordNet、HowNet、大连理工大学中文情感词汇文本库等。基于情感词典的文本情感分析的技术步骤通常先匹配原文本中与情感词典相对应的情感表达特征词，然后根据各特征词的表达方式综合计算其每一个特征词的情感得分，最后结合整个文本的情感得分总结文本的情感倾向。

Taboada\citeup{taboada2011lexicon}在原来情感词典的基础上进一步考虑了词语的词性，结合情感词和词性综合给出情感的倾向得分。该情感分析模型包含一个语义指向计算器（Semantic　orientation　calculator，SO-CAL），这个计算器首先抽取出文本中的形容词、动词、名词以及副词等情感方位词，然后结合各种情感方位词计算原来文本的情感指向，模型结合的情感指向和强调、弱化、否定等转移的价位得到文本最终的情感倾向。作者通过一系列的实验证明了基于情感词典和此种转移规则的模型具有很强的鲁棒性，在跨领域的的文本情感分析上也有良好的表现。孙建旺\citeup{孙建旺2014基于词典与机器学习的中文微博情感分析研究}等提出结合情感词典和机器学习两者的优势来解决微博情感分析的问题利用微博多层次结构对微博文本进行特征降维。此外，由于微博包含多种颜文字，表情符等特点，设计了对颜文字和表情符的情感计算方法，其实验证明了加入表情符等特征，对微博的情感分析效果得到了提高。

基于不同的上下文可能决定某些情感词的特点，具有一定的领域相关性。例如“高”在“质量高”的上下文中表达的是正面的情感倾向，但是如果在“消费高”的上下文则表达负面的情感倾向。Bollegala\citeup{bollegala2013cross}等人结合了不同领域对情感词的表达特点构造了领域相关的情感词典。实验证明结合领域知识的情感词典能在相对于的领域取得更好的效果。Li\citeup{li2012cross}提出一种相关领域自适应情感词的框架，能同步从标注训练语料中提取出的主题词和情感词，并进一步通过分析标注语料中主题词和情感词的关系来推导出未标注语料中与主题相关的情感词。

总体来看，基于情感词典/规则和知识库的情感分类准确率较高，但由于情感词典和常识库规模的限制，覆盖率较低。同时此类方法对分词、词性标注、规则匹配等的准确性要求较高，系统内部错误传递影响较大。

\BiSubsection{基于机器学习的文本情感分析相关技术}{2.2.2}

随着机器学习成功应用于其他领域的快速发展，对于文本情感分析的问题，大量的研究人员开始开展基于机器学习的文本情感分析的研究。基于机器学习的文本情感分析方法，首先通过特征工程抽取文本情感分析特征，然后通过抽取出来的特征词用机器学习能理解的数值表达文本。通过人工标注建立起特征表示数据和情感类标对的训练数据，通过各种已有的机器学习模型提取出训练集中特征和类标之间的映射关系的模型。Wang\citeup{wang2012baselines}等利用N元词组（N-gram）对文本情感进行建模，模型结合了朴素贝叶斯与支持向量机的两个模型。首先利用朴素贝叶斯的思想，计算每一个词组的对数计数概率r，公式如下：
\begin{equation}\label{f1favor}r=\log(\cfrac{\cfrac{p}{\|p_1\|}}{\cfrac{q}{\|q_1\|}})\end{equation}
\begin{equation}\label{f1favor}p=\alpha + \sum_{i:y^{(i)}=1}f^{(i)}\end{equation}
\begin{equation}\label{f1favor}p=\alpha + \sum_{i:y^{(i)}=-1}f^{(i)}\end{equation}

其中$y^{(i)}$为训练实例$i$的类标，$y^{(i)}\in\lbrace-1,1\rbrace$。其中$f^{(i)}$为训练实例$i$的特征向量，$f_{(i)}\in R^{\|V\|}$， $V$为特征集合 $\alpha$为平滑因子。

于上述r的计算公式可知，从训练语料中可以计算出每一个词语对于不同情感的倾向大小，所以利用我们已经计算的每一个词的r值，可以得到文本的特征表示，特征表示后的文本可以作为支持向量机的输入，通过支持向量机可以抽取出训练集中有关文本情感分析的模式。

Pang\citeup{pang2004sentimental}等研究者创新性的把文本主题分析的技术迁移应用到文本情感分析中，文本的话题分类主要根据与话题相关的主题词决定，但是表达情感的方式更加的多样化，需要考虑的因素更多。Pang把文本的情感分析看成一类特殊的主题分析，使用了在有监督学习上泛化能力较好的支持向量机、朴素贝叶斯、最大熵模型三种基础的分类模型。选用的分类特征为一元词组（Unigram）、二元词组（Bigram）、词性分析（POS）、形容词位置信息等。此研究通过组合特征和模型的交叉验证表明，三个分类器组合任意一个特征的性能都比基线模型要好，在有关电影影评的数据集上，一元词组（Unigram）结合支持向量机的模型取得了良好的效果。但是此研究实验也论证了文本的情感分析的性能还是和文本主题分析存在较大的差距，同时也佐证了文本情感分析对模型和特征也有更高的要求。

为了减少文本中无关的客观信息对文本情绪分析的干扰作用，Pang和lee对上述基于机器学习的文本情感分析模型进行了有针对性的改进，规避了文本客观消息的干扰，使模型更加专注于文本的主观信息。作者他们把原来的文本情感分析问题转换成以各字句连接图中最小割问题，应用了挖掘图中的最小割的分类器来寻找对情感分析有用的主观表达的句子，从而屏蔽掉客观消息的干扰。此研究的实验也论证了剔除客观信息的文本情感分析模型的性能得到显著的加强。

\BiSubsection{基于深度学习的文本情感分析相关技术}{2.2.3}

深度学习由于其更复杂的模型和更多的参数，比起以往的的机器学习方法在海量数据集上更有优势。且深度学习具有能够以端到端的形式构建模型的优势，不再需要人工筛选和总结大量特征，所以得到了情感分析研究者的关注。Socher\citeup{socher2010learning}等研究者为满足深度模型构建的需要，首先组织标注了斯坦福情感树库（Stanford Sentiment Treebank，SSTB）。斯坦福情感树库由11，855个电影评论句子组成，共包含215，154个不同短语，其中任意短语构成的节点和其他叶子节点均被标注为五类情感（强正面、正面、中性、负面、强负面）中的一个。Socher提出使用语法树和词汇向量表示任意长度的短语输入的递归神经张量网络，且其使用相同的张量组合函数来计算根节点向量，可得到句子中任意短语的情感向量表示。该模型可以利用树形结构捕捉情感变化和否定作用范围，对于转折结构中情感表达识别同样具有很好的效果。实验证明，RNTN模型在五分类的情感分析及二分类（“正”、“负”）的情感分析中都取得了历史最好成绩。

循环神经网络（Recurrent Neural Networks-RNN）已经在众多自然语言处理任务上取得了巨大成功。不同于传统过得前向反馈神经网络的同层节点无连接层于层之间节点有连接，循环神经网络引入了定向循环，可以处理序列数据。RNN中最大的缺陷是后面时间的节点对于前面节点的感知力下降，当网络深时训练效果下降。LSTM可以解决这一问题，目前LSTM是RNN中使用最广泛最成功的模型。

卷积神经网络不仅在图像处理上表现优异，在文本分类上同样表现不俗。kim\citeup{kim2014convolutional}提出的多卷积核文本分类CNN模型。模型第一层为预先训练好的词向量或者是随机初始化参数的词向量Embedding层，然后接一个宽度和词向量维数相同，长度通常为3、4、5的多个卷积核的卷积层，卷积层后是是较少参数的池化层，最大值池化层在分类的效果较好。池化层后的输出为文本提取出来的特征向量，最后连接一个全连接作为分类层。实验证明CNN在情感分析上能较好的性能。

\BiSection{文本立场分析相关技术}{2.3}
文本立场分析与文本情感分析有着本质的区别，文本立场分析更加关注文本反应出作者对于某一特定目标主题所持的立场和倾向。立场分析需要结合目标主题和情感信息，这比单独考虑文本的消息更加具有有挑战，对模型的建模能力也有更高的要求。作为一项特殊的情感分析任务，立场分析问题主要是在给定了目标的前提下，判断这个文本的立场是“支持”或“反对”。作者在文本中评价的目标不一定是立场分析给定的目标，也可能立场分析给定的目标并没有直接出现在文本中。即使作者在文本中对目标/实体的态度是积极的，但推断出来的结果可能是作者对给定目标持反对的立场。

具有强大学习能力的基于特征的机器学习算法能够充分学习到文本的语法、语义等特征，因此受到了研究者的广泛关注。本节将介绍有监督的立场分析方法和若监督的立场分析方法。考虑到深度学习模型的立场分析研究逐渐增多且有成为主流的趋势，将在2.4小节单独介绍基于深度学习模型的立场分析研究状况。


\BiSubsection{基于有监督机器学习的文本立场分析技术}{2.3.1}

Anand\citeup{anand2011cats}等作为立场分析问题较早的研究者之一，抽取了网络论坛上4837篇有关14个不同话题的讨论，构造了10种不同的特征。这10种特征包括一元词频、二元词频、长度、标点、线索词、句法依赖、语义依赖、广义依赖、上下文特征和LIWC（Liunguistics Inquiry Word Count）等。分别利用RIPPER和朴素贝叶斯两种算法验证了立场分析在不同特征集合下的效果。实验证明，应用了上下文特征可以有效提升实验效果，在不同子话题中同一分类模型表现有较大差异。对于Anand的研究，Hasan等研究者认为他们忽略了文本间意识形态和用户交互这两种对实验性能具有很大影响的约束。Hasan\citeup{hasan2013stance}在研究中的文本序列模型是以相邻文本间的用户交互约束建立的，并利用了CRFs来解决序列标注问题。该研究为每位文本作者的意识形态以ILP建立基于话题领域、作者的意识形态约束模型。并且在实验中得到了比原作者	正确率上2.9\%到10\%不等的提升。

社交文本以推特为例，具有长度较短且语言非正式等特点，Zhang\citeup{zhang2016ecnu}针对这些特点提出了两部的学习系统。将社交媒体文本的三个立场“支持”、“反对”和“其他”转化为两次两分类的任务。第一步进行文本相关性检测，通过此步可以将无关文本作为“其他”类型检测出来；第二步使用立场倾向检测模型，对文本进行“支持”“反对”二分类。该研究在传统语言特征外还应用了LDA（Latent Dirichlet Allocation）生成的话题相关性、主题只是、情感词汇、词嵌入和表情符等多种不同的特征组合，为每一组子话题数据分别使用线性回归模型（Linear Regression，LR）建立立场分析模型。并且考虑到不同话题数据分布具有差异，对这各个子模型验证了不同超参数和特征集的组合方式。最后用实验证明了对不同子任务和子话题使用不同的特征组合的方式是有效的。

除了不同特征组合可以起到提升立场分类效果的作用，构建有差异的分类器组合也同样可以提升模型的立场分类效果和泛化能力。Xu等\citeup{xu2016ensemble}提出了选用该段落向量、浅层语义分析、LDA和其他语言学特征等，在线性SVMs、RBF核SVMs、Adaboost随机森林和随机森林等分类器中测试分类性能。并且该模型采用了对基分类器线性组合的方式提升模型表现，具体如公式~\ref{a23333}~所示。
\begin{equation}\label{a23333}
p(C|x)=\sum_{i=1}^m w_i \cdot p_i(C|x)
\end{equation}

式中$p_i(C|x)$为文本$x$在第$i$个分类器中被预测成立场类别$C$的概率。

$w_i$为线性模型中及分类器第$i$个基分类器的权重。

$p(C|x)$为文本$x$在立场类别$C$中的概率。

实验证明，该模型可以提高文本立场分析的效果。

\BiSubsection{基于弱监督机器学习的文本立场分析技术}{2.3.2}

弱监督学习是一种基于噪声训练数据的半监督学习方式。不同于以往基于可靠训练数据的有监督学习方式，弱监督学习基于的是不严密的假设生成训练数据。在训练数据中更可能含有错误和大量噪声。但该方法可以避免人工标注的高昂成本，且能在新语料、新话题中具有较好适用性。

Johnson\citeup{johnson2016all}研究者提出了结合若干弱监督局部分类器的联合模型。每个局部分类器使用的训练语料为少量有立场和框架维度标注的种子集合，随后使用概率软逻辑框架组合各弱监督局部分类器。弱逻辑框架使用的训练数据是弱监督局部分类器的信息，之后利用合页-马尔科夫随机域 （hinge-loss Markov random fields，HL- MRFs）的图模型关系表示建立用于立场预测的规则。实验证明该模型能较准确的预测Twiiter中有关政治任务立场任务。

Ebrahimi\citeup{ebrahimi2016weakly}提出了使用关系自扩展来实现弱监督学习的立场分类法扩展种子训练集。定义了三种立场相关约束：相似文本表达的立场相似、具有朋友关系的作者立场相似和文本作者对话题的立场相似。Ebrabimi为了匹配含噪音的少量标注集合，首先使用若干短语模式，然后利用基于统计关系学习的合页马尔科夫随机域模型标注文本立场，最后使用结合词典、多元词组和情感类型为特征的线性核SVMs训练有监督的立场检测模型，并在SemEval英文数据集上具有较高的性能。

Dias\citeup{dias2016heuristics}提出了使用启发式规则的方法自动标注Twitter文本，可以解决弱监督学习中语料标注的问题。该方法可以达到两重目的，既可以使用监督学习算法自动创建训练语料库开发预测模型，又可以补充预测立场检测模型。Dias构建了7条启发式规则构建训练语料，分析了六个不同的立场分析任务，取得了可观的成果，加权F1值从52\%提升到了67\%。


\BiSection{基于深度学习的立场分析技术}{2.4}

近年来深度学习不仅在计算机视觉、语音识别等领域取得了卓越的成果，在自然语言处理领域中研究者开始采用深度学习模型。不同于传统机器学习方法的手动特征工程，深度学习模型采用端到端的分类模式，减少人为手工构造特征的工作量，能够自动抽取在参数学习中最优的特征表示。本节介绍深度学习模型在立场分析方法上的应用。

Mikolov\citeup{mikolov2010recurrent}提出了一种基于循环神经网络的语言模型。该网络是三层的神经网络结构，包含输入层、输出层和上下文表示层，上下文表示层的信息拼接了上一时间存储信息和当前时间输入信息，因此可以将全部历史信息保存在低纬度的向量空间中，大大增强了语言建模能力。实验表明，与已有的退避模型（Backoff Language Model）相比，使用多个 RNN-LM可以减少约50\%的困惑度（perplexity）。在“华尔街日报”任务上降低了18\%的错误率。Sundermeyer\citeup{sundermeyer2012lstm}在为解决RNN-LM模型在反向误差传播函数时梯度消失/爆炸带来的巨大影响，采用了结合长短时记忆单元的循环神经网络（LSTM）该单元包含三个门：输入门、输出门和遗忘门，这样的结构可以解决梯度缩放问题且计算代价小。该模型在标准语料库上的困惑度指标比RNN-LM模型低8\%。

Zarrella等\citeup{zarrella2016mitre}研究者利用了迁移学习的思想，首先利用word2vec skip-gram等无监督方法训练了单词和短语的词向量表示。采集了大量的无标注Twitter文本（218，279，858）。选取了词频高于100的词汇，然后用Word2vec模型预训练好了每一个词的256维度的词向量，后面通过词向量相似度选取比较关键的以\#为前缀主题标签，通过训练神经网络预测主题标签。后通过迁移学习的思想对网络结构进行微调来达到立场分析的目的然后通过主题标签预测辅助任务来学习句子向量，然后被微调用于标记样本的立场检测。实验结果显示，该方法在Semeval 2016英文数据集任务中微平均F1值为0.678。

Yu\citeup{yu2016stance}提出了基于双向LSTM-RNN的模型，此模型包括词嵌入输入层、卷积层、池化层、LSTM单元层、全连接分类层。卷积层的作用是在于提取词组中的局部特征，LSTM单元的作用是学习句子的全局语义特征，池化层的作用是保留卷积的位置不变性和较少模型参数。组合上述的句子特征表示连接全连接层进行分类。实验证明模型在NLPCC中文社交文本立场分析数据集具有较好的性能。

Wei\citeup{wei2016pkudblab}为了解决在弱监督立场分析中标注数据缺失的问题，使用了分成两步任务的框架。首先构建一个基础的二分类器，使用他们定义的softmax层在二分类训练数据中执行三分类任务。第一步利用有清晰倾向性的词汇和表情标注“支持”和“反对”两种立场，第二步将“支持”立场和“反对”立场概率差绝对值小于阈值的文本标注为第三类“中立”。以弱监督标注文本为基础，使用与有监督学习相似的深度学习模型得到的预测结果的方法改善了训练数据较少的问题。


\BiSection{本章小节}{2.5}


本章首先介绍了情感分析的常用技术和研究现状，然后从基于手工特征工程的机器学习方法和端到端的深度学习模型来年各个角度详细描述了立场分析检测的现有研究。基于特征筛选和分类器集成学习仍然是机器学习领域的主流，基于RNN/LSTM和CNNs等模型的工作是在深度学习领域上的主要方案。特有的预置话题包在分析任务任务中对最后的预测也起到了十分关键的作用，立场分析就有工作的重要方向就是如何将主题目标信息更好地利用上。